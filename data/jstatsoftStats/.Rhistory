example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
unlist(str_extract_all("This is a backslash: \\ ", "")
# meta characters in character classes
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
# backreferencing
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
# grouped matches
str_extract_all(example.obj, "([^ ]+) (sentence)")
str_match_all(example.obj, "([^ ]+) (sentence)")
# assertions
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
# do you think you can master regular expressions now?
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
# a note on the stringi package
# source: [https://goo.gl/XzEQai]
# stringr is built on top of the stringi package.
# stringr is convenient because it exposes a minimal set of functions, which have been carefully picked to handle the most common string manipulation functions.
# stringi is designed to be comprehensive. It contains almost every function you might ever need: stringi has 234 functions (compare that to stringr's 42)
# packages work very similarly; translating knowledge is easy (try stri_ instead of str_)
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
######################
### IT'S YOUR SHOT ###
######################
## 1. describe the types of strings that conform to the following regular expressions and construct an example that is matched by the regular expression.
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
"\\b[a-z]{1,4}\\b"
".*?\\.txt$"
"\\d{2}/\\d{2}/\\d{4}"
"<(.+?)>.+?</\\1>"
## 2. consider the mail address  chunkylover53[at]aol[dot]com.
# a) transform the string to a standard mail format using regular expressions.
# b) imagine we are trying to extract the digits in the mail address using [:digit:]. explain why this fails and correct the expression.
email <- "chunkylover53[at]aol[dot]com"
## string manipulation ----------
# inspect text
x <- stri_rand_lipsum(1)
str_view(x, "et")
str_view_all(x, "et")
example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
unlist(str_extract_all("This is a backslash: \ ", ""))
unlist(str_extract_all("This is a backslash: \ ", "\\"))
unlist(str_extract_all("This is a backslash: \ ", "\\\"))
# meta characters in character classes
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
# backreferencing
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
# grouped matches
str_extract_all(example.obj, "([^ ]+) (sentence)")
str_match_all(example.obj, "([^ ]+) (sentence)")
# assertions
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
# do you think you can master regular expressions now?
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
# a note on the stringi package
# source: [https://goo.gl/XzEQai]
# stringr is built on top of the stringi package.
# stringr is convenient because it exposes a minimal set of functions, which have been carefully picked to handle the most common string manipulation functions.
# stringi is designed to be comprehensive. It contains almost every function you might ever need: stringi has 234 functions (compare that to stringr's 42)
# packages work very similarly; translating knowledge is easy (try stri_ instead of str_)
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
######################
### IT'S YOUR SHOT ###
######################
## 1. describe the types of strings that conform to the following regular expressions and construct an example that is matched by the regular expression.
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
"\\b[a-z]{1,4}\\b"
".*?\\.txt$"
"\\d{2}/\\d{2}/\\d{4}"
"<(.+?)>.+?</\\1>"
## 2. consider the mail address  chunkylover53[at]aol[dot]com.
# a) transform the string to a standard mail format using regular expressions.
# b) imagine we are trying to extract the digits in the mail address using [:digit:]. explain why this fails and correct the expression.
email <- "chunkylover53[at]aol[dot]com"
## string manipulation ----------
# inspect text
x <- stri_rand_lipsum(1)
str_view(x, "et")
str_view_all(x, "et")
example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
unlist(str_extract_all("This is a backslash: \ ", "\\"))
unlist(str_extract_all("This is a backslash: \ ", fixed("\"))
# meta characters in character classes
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
# backreferencing
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
# grouped matches
str_extract_all(example.obj, "([^ ]+) (sentence)")
str_match_all(example.obj, "([^ ]+) (sentence)")
# assertions
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
# do you think you can master regular expressions now?
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
# a note on the stringi package
# source: [https://goo.gl/XzEQai]
# stringr is built on top of the stringi package.
# stringr is convenient because it exposes a minimal set of functions, which have been carefully picked to handle the most common string manipulation functions.
# stringi is designed to be comprehensive. It contains almost every function you might ever need: stringi has 234 functions (compare that to stringr's 42)
# packages work very similarly; translating knowledge is easy (try stri_ instead of str_)
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
######################
### IT'S YOUR SHOT ###
######################
## 1. describe the types of strings that conform to the following regular expressions and construct an example that is matched by the regular expression.
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
"\\b[a-z]{1,4}\\b"
".*?\\.txt$"
"\\d{2}/\\d{2}/\\d{4}"
"<(.+?)>.+?</\\1>"
## 2. consider the mail address  chunkylover53[at]aol[dot]com.
# a) transform the string to a standard mail format using regular expressions.
# b) imagine we are trying to extract the digits in the mail address using [:digit:]. explain why this fails and correct the expression.
email <- "chunkylover53[at]aol[dot]com"
## string manipulation ----------
# inspect text
x <- stri_rand_lipsum(1)
str_view(x, "et")
str_view_all(x, "et")
example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
str_extract_all(example.obj, "([^ ]+) (sentence)")
str_match_all(example.obj, "([^ ]+) (sentence)")
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "(?<!Blah )huge+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "(?<!Blah )huge.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
str_extract_all("munich, pisa, firenze", "\\b[a-z]{1,4}\\b")
str_extract_all("I am looking for words of max length four", "\\b[a-z]{1,4}\\b")
str_extract_all(c("test.dta", "log.txt", "foo.txt "), ".*?\\.txt$")
str_extract_all(c("test.dta", "this is a log.txt", "foo.txt "), ".*?\\.txt$")
str_extract_all(c("18/05/2017", "18.05.2017"), "\\d{2}/\\d{2}/\\d{4}")
str_extract_all(c("18/5/2017", "18.05.2017"), "\\d{1,2}/\\d{1,2}/\\d{4}")
str_extract_all("<br><i>hello</i>", "<(.+?)>.+?</\\1>")
example.obj
str_locate(example.obj, "tiny")
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
str_locate(example.obj, "tiny")
str_sub(example.obj, start = 35, end = 38)
str_sub(example.obj, start = 33, end = 38)
str_sub(example.obj, 35, 38) <- "huge"
example.obj
str_replace(example.obj, pattern = "huge", replacement = "giant")
str_replace(example.obj, pattern = "sentence", replacement = "house")
str_replace_all(example.obj, pattern = "sentence", replacement = "house")
example.obj
str_split(example.obj, "-") %>% unlist
str_split(example.obj, " ") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
(char.vec <- c("this", "and this", "and that"))
char.vec
?str_detect
str_detect(char.vec, "this")
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
str_dup(char.vec, 3)
length.char.vec <- str_length(char.vec)
length.char.vec
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
?str_trim
paste("text", "manipulation")
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
?agrep
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
?agrep
agrepl("Donald Trump", "Barack Obama", max.distance = list(all = 3))
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
?remoteDriver
source("00-course-setup.r")
?remoteDriver
remDr <- remoteDriver$new()
remDr$open()
startServer()
driver<- rsDriver()
?rsDriver
?rsDriver
rD <- rsDriver()
system("java -jar selenium-server-standalone-3.4.0.jar")
system("java -jar selenium-server-standalone-3.1.0.jar")
system("java -jar selenium-server-standalone-2.53.1.jar")
system("java -version")
system("java -jar selenium-server-standalone-3.4.0.jar")
system("dir")
system("ls")
browseURL("http://ropensci.org/")
browseURL("http://arxiv.org/help/api/index")
load("/Users/munzerts/rkeys.RDa")
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl unload ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl unload ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl start spiegelheadlines")
system("launchctl list")
system("launchctl stop spiegelheadlines")
system("launchctl unload ~/Library/LaunchAgents/spiegelheadlines.plist")
setwd(wd)
tempwd <- ("data/jstatsoftStats")
source("00-course-setup.r")
wd <- getwd()
wd
# set temporary working directory
setwd(wd)
tempwd <- ("data/jstatsoftStats")
dir.create(tempwd)
setwd(tempwd)
browseURL("http://www.jstatsoft.org/")
baseurl <- "http://www.jstatsoft.org/article/view/v"
seq(1,77,1)
volurl <- paste0("0", seq(1,77,1))
volurl
volurl[1:9] <- paste0("00", seq(1, 9, 1))
volurl
brurl <- paste0("0", seq(1,9,1))
brurl
?seq
1:77
brurl <- paste0("0", seq(1,9,1))
brurl
urls_list <- paste0(baseurl, volurl)
urls_list
paste("hello", "world")
paste0("hello", "world")
rep(urls_list, each = 9)
urls_list <- paste0(rep(urls_list, each = 9), "i", brurl)
urls_list
names <- paste0(rep(volurl, each = 9), "_", brurl, ".html")
names
folder <- "html_articles/"
dir.create(folder)
# download pages
folder <- "html_articles/"
dir.create(folder)
for (i in 1:length(urls_list)) {
if (!file.exists(paste0(folder, names[i]))) {
download.file(urls_list[i], destfile = paste0(folder, names[i]))
Sys.sleep(runif(1, 0, 1))
}
}
list_files <- list.files(folder, pattern = "0.*")
list_files
list_files_path <-  list.files(folder, pattern = "0.*", full.names = TRUE)
list_files_path
length(list_files)
files_size <- sapply(list_files_path, file.size)
files_size
table(files_size) %>% sort()
delete_files <- list_files_path[files_size == 27863]
delete_files
sapply(delete_files, file.remove)
list_files_path <-  list.files(folder, pattern = "0.*", full.names = TRUE) # update list of files
list_files_path
i=1
html_out <- read_html(list_files_path[i])
table_out <- html_table(html_out, fill = TRUE)[[6]]
table_out
View(table_out)
# import pages and extract content
authors <- character()
title <- character()
statistics <- character()
numViews <- numeric()
datePublish <- character()
for (i in 1:length(list_files_path)) {
html_out <- read_html(list_files_path[i])
table_out <- html_table(html_out, fill = TRUE)[[6]]
authors[i] <- table_out[1,2]
title[i] <- table_out[2,2]
statistics[i] <- table_out[4,2]
numViews[i] <- statistics[i] %>% str_extract("[[:digit:]]+") %>% as.numeric()
datePublish[i] <- statistics[i] %>% str_extract("[[:digit:]]{4}-[[:digit:]]{2}-[[:digit:]]{2}.$") %>% str_replace("\\.", "")
}
?download.file
dat <- data.frame(authors = authors, title = title, numViews = numViews, datePublish = datePublish)
head(dat)
View(dat)
dattop <- dat[order(dat$numViews, decreasing = TRUE),]
dattop[1:10,]
plot(density(dat$numViews, from = 0), yaxt="n", ylab="", xlab="Number of views", main="Distribution of article page views in JSTATSOFT")
?read_html
?html_nodes
?html_session
browseURL("http://www.whoishostingthis.com/tools/user-agent/")
uastring <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
session <- html_session("http://www.google.com", user_agent(uastring))
session
html_form(session)
search <- html_form(session)[[1]]
search
search
form <- set_values(search, q = "pubs firenze")
form
google_search <- submit_form(session, form)
google_search
url_parsed <- read_html(google_search)
hits_text <- html_nodes(url_parsed, css = ".r a") %>% html_text()
hits_text
hits_links <- html_nodes(url_parsed, css = ".r a") %>% html_attr("href")
hits_links
url <- "http://read-able.com/"
browseURL(url)
url_parsed <- read_html(url)
html_form(url_parsed)
readable <- html_form(url_parsed)[[2]]
url <- "http://read-able.com/"
url_parsed <- read_html(url)
html_form(url_parsed)
readable <- html_form(url_parsed)[[2]]
sentence <- '"It is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts." - Arthur Conan Doyle, Sherlock Holmes'
readable_form <- set_values(readable, directInput = sentence)
session <- html_session(url, user_agent(uastring))
readable_search <- submit_form(session, readable_form)
url_parsed <- read_html(readable_search)
html_table(url_parsed)

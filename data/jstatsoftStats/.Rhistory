warnings()
pos
for (i in 1:length(unique_institutions))
pos[i,] <- geocode(unique_institutions[i], source = "google", force = "FALSE")
}
i
unique_institutions
unique_institutions <- unique_institutions[!is.na(unique_institutions)]
for (i in 1:length(unique_institutions)) {
pos[i,] <- geocode(unique_institutions[i], source = "google", force = "FALSE")
}
warnings()
pos
post$institution <- unique_institutions
pos$institution <- unique_institutions
View(pos)
save(pos, file="institutions2015_geo.RData")
head(pos)
names(rev_df)
foo <- merge(rev_df, pos, by. = "institution")
foo <- merge(rev_df, pos, by. = "institution", all = T)
names(rev_df)
naes(pos)
names(pos)
?cbind.fill
foo <- merge(rev_df, pos, by = "institution", all = T)
View(foo)
rev_geo <- merge(rev_df, pos, by = "institution", all = T)
mapWorld <- borders("world")
## step 6: plot reviewers, worldwide
mapWorld <- borders("world")
map <-
ggplot() +
mapWorld +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-60,70))
map
?borders
mapWorld <- borders("europe")
mapEurope <- get_map(location = 'Europe', zoom = 4)
map <-
ggplot() +
mapEurope +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-60,70))
map
mapEurope <- get_map(location = 'Europe', zoom = 4)
map <-
ggplot() +
mapEurope +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-60,70))
map
mapEurope
map <-
ggplot() +
ggmap(mapEurope) +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-60,70))
map
ggmap(mapEurope)
map <-
ggmap(mapEurope) +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-60,70))
map
ggmap(mapEurope)
map <-
ggmap(mapEurope) +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T) +
theme_bw()
map
ggmap(mapEurope) +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T)
aes(x=rev_geo$lon, y=rev_geo$lat)
y=rev_geo$lat
y
rev_geo <- merge(rev_df, pos, by = "institution", all = T)
View(rev_geo)
rev_geo <- rev_geo[!is.na(rev_geo$lat)]
rev_geo <- rev_geo[!is.na(rev_geo$lat),]
## step 6: plot reviewers, worldwide
mapWorld <- borders("world")
map <-
ggplot() +
mapWorld +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-60,70))
map
## step 7: plot reviewers, italy
mapEurope <- get_map(location = 'Europe', zoom = 4)
map <-
ggmap(mapEurope) +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T)
map
=rev_geo$lon
rev_geo$lon
## step 7: plot reviewers, italy
mapEurope <- get_map(location = 'World', zoom = 1)
map <-
ggmap(mapEurope) +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T)
map
## step 7: plot reviewers, italy
mapEurope <- get_map(location = 'World', zoom = 1)
map <-
ggmap(mapEurope) +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T)
map
## step 7: plot reviewers, italy
mapEurope <- get_map(location = 'World', zoom = 1)
map <-
ggmap(mapEurope) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color="#F54B1A90", size=3 ,
na.rm=T)
map
## step 6: plot reviewers, worldwide
mapWorld <- get_map(location = 'World', zoom = 2)
map <-
ggmap(mapWorld) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color="#F54B1A90", size=3 ,
na.rm=T)
map
## step 6: plot reviewers, worldwide
mapWorld <- get_map(location = 'World', zoom = 2)
map <-
ggmap(mapWorld) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color = "#F54B1A90", size = 1 ,
na.rm = T)
map
## step 6: plot reviewers, worldwide
mapWorld <- get_map(location = 'World', zoom = 1)
map <-
ggmap(mapWorld) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color = "#F54B1A90", size = 1 ,
na.rm = T)
map
?ggmap
## step 6: plot reviewers, worldwide
mapWorld <- get_map(location = 'World', zoom = 1)
map <-
ggmap(mapWorld, maprange = TRUE) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color = "#F54B1A90", size = 1 ,
na.rm = T)
map
?get_map
## step 6: plot reviewers, worldwide
mapWorld <- get_map(location = 'World', zoom = 1, size = c(640, 480))
map <-
ggmap(mapWorld) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color = "#F54B1A90", size = 1 ,
na.rm = T)
map
## step 6: plot reviewers, worldwide
mapWorld <- get_map(location = 'World', zoom = 1, size = c(480, 640))
map <-
ggmap(mapWorld) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color = "#F54B1A90", size = 1 ,
na.rm = T)
map
## step 6: plot reviewers, worldwide
mapWorld <- get_map(location = 'World', zoom = 2)
map <-
ggmap(mapWorld) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color = "#F54B1A90", size = 1 ,
na.rm = T)
map
mapWorld <- map_data ("world")
map <-
ggmap(mapWorld) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color = "#F54B1A90", size = 1 ,
na.rm = T)
map
mapWorld
## step 6: plot reviewers, worldwide
mapWorld <- borders("world")
map <-
ggplot() +
mapWorld +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=3 ,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-60,70))
map
## step 6: plot reviewers, worldwide
mapWorld <- borders("world")
map <-
ggplot() +
mapWorld +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=2 ,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-60,70))
map
## step 6: plot reviewers, worldwide
mapWorld <- borders("world")
map <-
ggplot() +
mapWorld +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=1,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-70,80))
map
## step 7: plot reviewers, italy
mapEurope <- get_map(location = 'Europe', zoom = 4)
map <-
ggmap(mapEurope) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color="#F54B1A90", size=3 ,
na.rm=T)
map
## step 7: plot reviewers, Italy
mapItaly <- get_map(location = 'Italy', zoom = 4)
map <-
ggmap(mapItaly) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color="#F54B1A90", size = 1,
na.rm=T)
map
## step 7: plot reviewers, Italy
mapItaly <- get_map(location = 'Italy', zoom = 6)
map <-
ggmap(mapItaly) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color="#F54B1A90", size = 1,
na.rm=T)
map
url <- "https://www.buzzfeed.com/?country=us"
browseURL(url)
url_parsed <- read_html(url)
class(url_parsed)
html_structure(url_parsed)
as_list(url_parsed)
headings_nodes <- html_nodes(url_parsed, css = ".lede__link")
headings_nodes
url <- "https://www.nytimes.com"
url_parsed <- read_html(url)
class(url_parsed)
html_structure(url_parsed)
as_list(url_parsed)
headings_nodes <- html_nodes(url_parsed, css = ".story-heading")
headings_nodes
headings <- html_text(headings_nodes)
headings <- str_replace_all(headings, "\\n", "") %>% str_trim()
headings
headings <- str_replace_all(headings, "\\n", "") %>% str_trim()
head(headings)
length(headings)
str_detect(headings, "Trump") %>% table()
browseURL("https://www.jstatsoft.org/about/editorialTeam")
url <- "https://en.wikipedia.org/wiki/Joint_Statistical_Meetings"
browseURL(url)
url_parsed <- read_html(url)
tables <- html_table(url_parsed, fill = TRUE)
tables
meetings <- tables[[2]]
class(meetings)
head(meetings)
table(meetings$Location) %>% sort()
setwd("../../")
setwd(wd)
tempwd <- ("data/jstatsoftStats")
dir.create(tempwd)
setwd("../../")
tempwd <- ("data/jstatsoftStats")
dir.create(tempwd)
setwd(tempwd)
browseURL("http://www.jstatsoft.org/")
# construct list of urls
baseurl <- "http://www.jstatsoft.org/article/view/v"
volurl <- paste0("0", seq(1,73,1))
volurl[1:9] <- paste0("00", seq(1, 9, 1))
brurl <- paste0("0", seq(1,9,1))
urls_list <- paste0(baseurl, volurl)
urls_list <- paste0(rep(urls_list, each = 9), "i", brurl)
names <- paste0(rep(volurl, each = 9), "_", brurl, ".html")
urls_list
length(list_files)
list_files <- list.files(folder, pattern = "0.*")
folder <- "html_articles/"
list_files <- list.files(folder, pattern = "0.*")
list_files_path <-  list.files(folder, pattern = "0.*", full.names = TRUE)
length(list_files)
files_size <- sapply(list_files_path, file.size)
table(files_size) %>% sort()
delete_files <- list_files_path[files_size == 27863]
sapply(delete_files, file.remove)
list_files_path <-  list.files(folder, pattern = "0.*", full.names = TRUE) # update list of files
# import pages and extract content
authors <- character()
title <- character()
statistics <- character()
numViews <- numeric()
datePublish <- character()
for (i in 1:length(list_files_path)) {
html_out <- read_html(list_files_path[i])
table_out <- html_table(html_out, fill = TRUE)[[6]]
authors[i] <- table_out[1,2]
title[i] <- table_out[2,2]
statistics[i] <- table_out[4,2]
numViews[i] <- statistics[i] %>% str_extract("[[:digit:]]+") %>% as.numeric()
datePublish[i] <- statistics[i] %>% str_extract("[[:digit:]]{4}-[[:digit:]]{2}-[[:digit:]]{2}.$") %>% str_replace("\\.", "")
}
dat <- data.frame(authors = authors, title = title, numViews = numViews, datePublish = datePublish)
head(dat)
# download statistics
dattop <- dat[order(dat$numViews, decreasing = TRUE),]
dattop[1:10,]
summary(dat$numViews)
plot(density(dat$numViews, from = 0), yaxt="n", ylab="", xlab="Number of views", main="Distribution of article page views in JSTATSOFT")
?html_node
?html_form
?submit_form
html_form(read_html("http://www.google.com"))
search <- html_form(read_html("http://www.google.com"))[[1]]
search
class(search)
?html_form
set_values(search, q = "pubs firenze")
set_values(search, hl = "en")
session <- html_session("http://www.google.com"", user_agent(uastring))
search <- html_form(read_html("http://www.google.com"))[[1]]
class(search)
set_values(search, q = "pubs firenze", hl = "en")
set_values(search, hl = "en")
# set local directory
setwd(paste0(basepath, "\\scenario-forms"))
## GET forms
# inspect webpage
browseURL("http://wordnetweb.princeton.edu/perl/webwn")
# manual request
query <- "trust"
wordnetFun <- function(query) {
url <- sprintf("http://wordnetweb.princeton.edu/perl/webwn?s=%s&sub=Search+WordNet", query)
getURL(url)
}
url <- wordnetFun("trust")
url_parsed <- htmlParse(url)
nodes <- xpathSApply(url_parsed, "//li", xmlValue)
# retrieve form
url        <- "http://wordnetweb.princeton.edu/perl/webwn"
html_form   <- getURL(url, curl = handle)
parsed_form <- htmlParse(html_form)
html_form(parsed_form)
# send GET request
html_form_res   <- getForm(uri = url, curl = handle, s = "data")
parsed_form_res <- htmlParse(html_form_res)
xpathApply(parsed_form_res,"//li", xmlValue)
## POST forms
# goal: gathering data from read-able at http://read-able.com/
browseURL("http://read-able.com/")
# post form
url  <- "http://read-able.com/"
form <- htmlParse(getURL(url = url, curl = handle))
html_form(form)
xpathApply(form, "//form[2]")
sentence <- '"It is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts." - Arthur Conan Doyle, Sherlock Holmes'
res <- postForm(uri=str_c(url, "check.php"),
curl=handle,
style="POST",
directInput=sentence)
readHTMLTable(res)
### ---------------- EXERCISE ---------------- ###
# Use the service at quipqiup.com to solve the secret written below. Obviously, se R to post the results!
secret <- "PBATENGHYNGVBAF LBH UNIR YRNEARQ GUR ONFVPF BS JRO FPENCVAT JVGU E ABJ UNIR SHA JVGU PENJYVAT LBHE BJA QNGN NAQ QB ABG SBETRG GB FGNL SEVRAQYL BA GUR JRO"
### glossary: rvest's main functions --------------
read_html()
html_nodes()
html_tag()
html_text()
html_attr()
html_attrs()
read_xml()
xml_nodes()
xml_tag()
xml_text()
xml_attr()
xml_attrs()
html_table()
html_form()
set_values()
submit_form()
guess_encoding()
repair_encoding()
html_session()
jump_to()
follow_link()
back()
forward()
submit_form()
session <- html_session("http://www.google.com", user_agent(uastring))
uastring <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
session <- html_session("http://www.google.com", user_agent(uastring))
?html_session
search <- html_form(session)[[1]]
search
class(search)
set_values(search, q = "pubs firenze", hl = "en")
browseURL("http://www.whoishostingthis.com/tools/user-agent/")
uastring <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
session <- html_session("http://www.google.com", user_agent(uastring))
search <- html_form(session)[[1]]
class(search)
search
set_values(search, q = "pubs firenze")
submit_geturl(session, form)
submit_form(session, form)
?submit_form
form <- set_values(search, q = "pubs firenze")
submit_form(session, form)
google_search <- submit_form(session, form)
google_search
class(google_search)
url_parsed <- read_html(google_search)
nodes <- html_nodes(url_parsed, css = ".r a")
nodes
nodes <- html_nodes(url_parsed, css = ".r a") %>% html_text()
nodes
hits_text <- html_nodes(url_parsed, css = ".r a") %>% html_text()
?html_attr
hits_links <- html_nodes(url_parsed, css = ".r a") %>% html_attrs(href) %>% html_text()
hits_links <- html_nodes(url_parsed, css = ".r a") %>% html_attr(href) %>% html_text()
hits_links <- html_nodes(url_parsed, css = ".r a") %>% html_attr("href") %>% html_text()
hits_links <- html_nodes(url_parsed, css = ".r a") %>% html_attr("href")
hits_links
search <- html_form(session)[[1]]
search
search
form <- set_values(search, q = "pubs firenze", hl = "en")
?set_values
search <- html_form(session)[[1]]
search
html_form(session)
?jump_to
?set_values
browseURL("http://wordnetweb.princeton.edu/perl/webwn")
url_parsed <- read_html(url)
html_form(url_parsed)
url <- "http://wordnetweb.princeton.edu/perl/webwn"
url_parsed <- read_html(url)
html_form(url_parsed)
wordnet_form <- set_values(wordnet, s = "data")
wordnet <- html_form(url_parsed)[[1]]
wordnet_form <- set_values(wordnet, s = "data")
session <- html_session(url, user_agent(uastring))
wordnet_form <- set_values(wordnet, s = "data")
submit_form(session, wordnet_form)
wordnet_search <- submit_form(session, wordnet_form)
url_parsed <- read_html(wordnet_search)
url_parsed %>% html_nodes(li)
url_parsed %>% html_nodes("li")
url_parsed %>% html_nodes("li") %>% html_text()
wordnet_form <- set_values(wordnet, s = "data", o2 = "1")
wordnet_search <- submit_form(session, wordnet_form)
url_parsed <- read_html(wordnet_search)
url_parsed %>% html_nodes("li") %>% html_text()
?html_form
url <- "http://read-able.com/"
browseURL(url)
url_parsed <- read_html(url)
html_form(url_parsed)
readable <- html_form(url_parsed)[[2]]
session <- html_session(url, user_agent(uastring))
?submit_form
sentence <- '"It is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts." - Arthur Conan Doyle, Sherlock Holmes'
readable_form <- set_values(readable, directInput = sentence)
session <- html_session(url, user_agent(uastring))
submit_form(session, readable_form)
readable_search <- submit_form(session, readable_form)
url_parsed <- read_html(readable_search)
html_table(url_parsed)

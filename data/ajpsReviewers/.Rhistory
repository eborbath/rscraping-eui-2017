stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
######################
### IT'S YOUR SHOT ###
######################
## 1. describe the types of strings that conform to the following regular expressions and construct an example that is matched by the regular expression.
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
"\\b[a-z]{1,4}\\b"
".*?\\.txt$"
"\\d{2}/\\d{2}/\\d{4}"
"<(.+?)>.+?</\\1>"
## 2. consider the mail address  chunkylover53[at]aol[dot]com.
# a) transform the string to a standard mail format using regular expressions.
# b) imagine we are trying to extract the digits in the mail address using [:digit:]. explain why this fails and correct the expression.
email <- "chunkylover53[at]aol[dot]com"
## string manipulation ----------
# inspect text
x <- stri_rand_lipsum(1)
str_view(x, "et")
str_view_all(x, "et")
example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
unlist(str_extract_all("This is a backslash: \\ ", "")
# meta characters in character classes
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
# backreferencing
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
# grouped matches
str_extract_all(example.obj, "([^ ]+) (sentence)")
str_match_all(example.obj, "([^ ]+) (sentence)")
# assertions
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
# do you think you can master regular expressions now?
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
# a note on the stringi package
# source: [https://goo.gl/XzEQai]
# stringr is built on top of the stringi package.
# stringr is convenient because it exposes a minimal set of functions, which have been carefully picked to handle the most common string manipulation functions.
# stringi is designed to be comprehensive. It contains almost every function you might ever need: stringi has 234 functions (compare that to stringr's 42)
# packages work very similarly; translating knowledge is easy (try stri_ instead of str_)
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
######################
### IT'S YOUR SHOT ###
######################
## 1. describe the types of strings that conform to the following regular expressions and construct an example that is matched by the regular expression.
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
"\\b[a-z]{1,4}\\b"
".*?\\.txt$"
"\\d{2}/\\d{2}/\\d{4}"
"<(.+?)>.+?</\\1>"
## 2. consider the mail address  chunkylover53[at]aol[dot]com.
# a) transform the string to a standard mail format using regular expressions.
# b) imagine we are trying to extract the digits in the mail address using [:digit:]. explain why this fails and correct the expression.
email <- "chunkylover53[at]aol[dot]com"
## string manipulation ----------
# inspect text
x <- stri_rand_lipsum(1)
str_view(x, "et")
str_view_all(x, "et")
example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
unlist(str_extract_all("This is a backslash: \ ", ""))
unlist(str_extract_all("This is a backslash: \ ", "\\"))
unlist(str_extract_all("This is a backslash: \ ", "\\\"))
# meta characters in character classes
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
# backreferencing
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
# grouped matches
str_extract_all(example.obj, "([^ ]+) (sentence)")
str_match_all(example.obj, "([^ ]+) (sentence)")
# assertions
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
# do you think you can master regular expressions now?
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
# a note on the stringi package
# source: [https://goo.gl/XzEQai]
# stringr is built on top of the stringi package.
# stringr is convenient because it exposes a minimal set of functions, which have been carefully picked to handle the most common string manipulation functions.
# stringi is designed to be comprehensive. It contains almost every function you might ever need: stringi has 234 functions (compare that to stringr's 42)
# packages work very similarly; translating knowledge is easy (try stri_ instead of str_)
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
######################
### IT'S YOUR SHOT ###
######################
## 1. describe the types of strings that conform to the following regular expressions and construct an example that is matched by the regular expression.
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
"\\b[a-z]{1,4}\\b"
".*?\\.txt$"
"\\d{2}/\\d{2}/\\d{4}"
"<(.+?)>.+?</\\1>"
## 2. consider the mail address  chunkylover53[at]aol[dot]com.
# a) transform the string to a standard mail format using regular expressions.
# b) imagine we are trying to extract the digits in the mail address using [:digit:]. explain why this fails and correct the expression.
email <- "chunkylover53[at]aol[dot]com"
## string manipulation ----------
# inspect text
x <- stri_rand_lipsum(1)
str_view(x, "et")
str_view_all(x, "et")
example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
unlist(str_extract_all("This is a backslash: \ ", "\\"))
unlist(str_extract_all("This is a backslash: \ ", fixed("\"))
# meta characters in character classes
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
# backreferencing
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
# grouped matches
str_extract_all(example.obj, "([^ ]+) (sentence)")
str_match_all(example.obj, "([^ ]+) (sentence)")
# assertions
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
# do you think you can master regular expressions now?
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
# a note on the stringi package
# source: [https://goo.gl/XzEQai]
# stringr is built on top of the stringi package.
# stringr is convenient because it exposes a minimal set of functions, which have been carefully picked to handle the most common string manipulation functions.
# stringi is designed to be comprehensive. It contains almost every function you might ever need: stringi has 234 functions (compare that to stringr's 42)
# packages work very similarly; translating knowledge is easy (try stri_ instead of str_)
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
######################
### IT'S YOUR SHOT ###
######################
## 1. describe the types of strings that conform to the following regular expressions and construct an example that is matched by the regular expression.
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
"\\b[a-z]{1,4}\\b"
".*?\\.txt$"
"\\d{2}/\\d{2}/\\d{4}"
"<(.+?)>.+?</\\1>"
## 2. consider the mail address  chunkylover53[at]aol[dot]com.
# a) transform the string to a standard mail format using regular expressions.
# b) imagine we are trying to extract the digits in the mail address using [:digit:]. explain why this fails and correct the expression.
email <- "chunkylover53[at]aol[dot]com"
## string manipulation ----------
# inspect text
x <- stri_rand_lipsum(1)
str_view(x, "et")
str_view_all(x, "et")
example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
str_extract_all(example.obj, "([^ ]+) (sentence)")
str_match_all(example.obj, "([^ ]+) (sentence)")
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "(?<!Blah )huge+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "(?<!Blah )huge.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
str_extract_all("Phone 150$, PC 690$", "[0-9]+\\$") # example
str_extract_all("munich, pisa, firenze", "\\b[a-z]{1,4}\\b")
str_extract_all("I am looking for words of max length four", "\\b[a-z]{1,4}\\b")
str_extract_all(c("test.dta", "log.txt", "foo.txt "), ".*?\\.txt$")
str_extract_all(c("test.dta", "this is a log.txt", "foo.txt "), ".*?\\.txt$")
str_extract_all(c("18/05/2017", "18.05.2017"), "\\d{2}/\\d{2}/\\d{4}")
str_extract_all(c("18/5/2017", "18.05.2017"), "\\d{1,2}/\\d{1,2}/\\d{4}")
str_extract_all("<br><i>hello</i>", "<(.+?)>.+?</\\1>")
example.obj
str_locate(example.obj, "tiny")
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
str_locate(example.obj, "tiny")
str_sub(example.obj, start = 35, end = 38)
str_sub(example.obj, start = 33, end = 38)
str_sub(example.obj, 35, 38) <- "huge"
example.obj
str_replace(example.obj, pattern = "huge", replacement = "giant")
str_replace(example.obj, pattern = "sentence", replacement = "house")
str_replace_all(example.obj, pattern = "sentence", replacement = "house")
example.obj
str_split(example.obj, "-") %>% unlist
str_split(example.obj, " ") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
(char.vec <- c("this", "and this", "and that"))
char.vec
?str_detect
str_detect(char.vec, "this")
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
str_dup(char.vec, 3)
length.char.vec <- str_length(char.vec)
length.char.vec
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
?str_trim
paste("text", "manipulation")
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
?agrep
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
?agrep
agrepl("Donald Trump", "Barack Obama", max.distance = list(all = 3))
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[firenze]")
## goals ------------------------
# fetch list of AJPS reviewers from PDFs
# locate them on a map
## tasks ------------------------
# downloading PDF files
# importing them into R (as plain text)
# extract information via regex
# geocoding
## packages ---------------------
library(stringr) # string processing
library(rvest) # scraping suite
library(ggmap) # geocoding
## directory ---------------------
wd <- ("./data/ajpsReviewers")
dir.create(wd)
setwd(wd)
url <- "http://ajps.org/list-of-reviewers/"
browseURL(url)
content <- read_html(url)
anchors <- html_nodes(content, xpath = "//a")
hrefs <- html_attr(anchors, "href")
hrefs
hrefs
basename(hrefs)
pdfs <- hrefs[ str_detect(basename(hrefs), ".*\\d{4}.*pdf") ]
pdfs
pdf_names <- str_extract(basename(pdfs), "\\d{4}") %>% paste0("reviewers", ., ".pdf")
pdf_names
pdfs
for(i in seq_along(pdfs)) {
download.file(pdfs[i], pdf_names[i], mode="wb")
}
rev_raw <- pdf_text("reviewers2015.pdf")
library(pdftools)
class(rev_raw)
rev_raw <- pdf_text("reviewers2015.pdf")
class(rev_raw)
rev_raw
rev_all <- rev_raw %>% str_split("\\n") %>% unlist
rev_all
surname <- str_extract(rev_all, "[[:alpha:]-]+")
surname
rev_all
prename <- str_extract(rev_all, " [.[:alpha:]]+")
prename
rev_df <- data.frame(raw = rev_all, surname = surname, prename = prename, stringsAsFactors = F)
head(rev_df)
View(rev_df)
rev_all <- rev_raw %>% str_split("\\n") %>% unlist
surname <- str_extract(rev_all, "[[:alpha:]-]+")
prename <- str_extract(rev_all, " [.[:alpha:]]+")
rev_df <- data.frame(raw = rev_all, surname = surname, prename = prename, stringsAsFactors = F)
rev_df$institution <- NA
for(i in 1:nrow(rev_df)) {
rev_df$institution[i] <- rev_df$raw[i] %>% str_replace(rev_df$surname[i], "") %>% str_replace(rev_df$prename[i], "") %>% str_trim()
}
View(rev_df)
head(rev_df)
rev_df <- rev_df[-c(1,2),]
rev_df <- rev_df[!is.na(rev_df$surname),]
head(rev_df)
dim(rev_df)
## step 5: geocode reviewers/institutions
# geocoding takes a while -> save results
# 2500 requests allowed per day
pos <- data.frame(lon = NA, lat = NA)
unique_institutions <- unique(rev_df$institution)
unique_institutions <- unique_institutions[!is.na(unique_institutions)]
if (!file.exists("institutions2015_geo.RData")){}
for (i in 1:length(unique_institutions)) {
pos[i,] <- geocode(unique_institutions[i], source = "google", force = "FALSE")
}
dir()
## step 5: geocode reviewers/institutions
# geocoding takes a while -> save results
# 2500 requests allowed per day
pos <- data.frame(lon = NA, lat = NA)
unique_institutions <- unique(rev_df$institution)
unique_institutions <- unique_institutions[!is.na(unique_institutions)]
if (!file.exists("institutions2015_geo.RData")){
for (i in 1:length(unique_institutions)) {
pos[i,] <- geocode(unique_institutions[i], source = "google", force = "FALSE")
}
pos$institution <- unique_institutions
save(pos, file="institutions2015_geo.RData")
} else {
load("institutions2013_geo.RData")
}
head(pos)
## step 5: geocode reviewers/institutions
# geocoding takes a while -> save results
# 2500 requests allowed per day
pos <- data.frame(lon = NA, lat = NA)
unique_institutions <- unique(rev_df$institution)
unique_institutions <- unique_institutions[!is.na(unique_institutions)]
if (!file.exists("institutions2015_geo.RData")){
for (i in 1:length(unique_institutions)) {
pos[i,] <- geocode(unique_institutions[i], source = "google", force = "FALSE")
}
pos$institution <- unique_institutions
save(pos, file="institutions2015_geo.RData")
} else {
load("institutions2015_geo.RData")
}
head(pos)
rev_geo <- merge(rev_df, pos, by = "institution", all = T)
## step 6: plot reviewers, worldwide
mapWorld <- borders("world")
map <-
ggplot() +
mapWorld +
geom_point(aes(x=rev_geo$lon, y=rev_geo$lat) ,
color="#F54B1A90", size=1,
na.rm=T) +
theme_bw() +
coord_map(xlim=c(-180, 180), ylim=c(-70,80))
map
## step 7: plot reviewers, Italy
mapItaly <- get_map(location = 'Italy', zoom = 6)
map <-
ggmap(mapItaly) +
geom_point(data = rev_geo, aes(x= lon, y = lat) ,
color="#F54B1A90", size = 1,
na.rm=T)
map
